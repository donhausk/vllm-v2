{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QUERY_TEMPLATE_MULTICHOICE = \"\"\"\n",
    "Answer the following multiple choice question. The last line of your response should be of the following format: 'Answer: $LETTER' (without quotes) where LETTER is one of ABCD. Think step by step before answering.\n",
    "\n",
    "{Question}\n",
    "\n",
    "A) {A}\n",
    "B) {B}\n",
    "C) {C}\n",
    "D) {D}\n",
    "\"\"\".strip()\n",
    "\n",
    "ANSWER_PATTERN_MULTICHOICE = r\"(?i)Answer[ \\t]*:[ \\t]*\\$?([A-D])\\$?\"\n",
    "ANSWER_PATTERN = r\"(?i)Answer\\s*:\\s*([^\\n]+)\"\n",
    "MULTILINGUAL_ANSWER_PATTERN_TEMPLATE = (\n",
    "    \"(?i){}[ \\t]*([A-D]|[أ-د]|[অ]|[ব]|[ড]|[ঢ]|[Ａ]|[Ｂ]|[Ｃ]|[Ｄ])\"\n",
    ")\n",
    "# All the different ways \"Answer\" is written in different languages\n",
    "MULTILINGUAL_ANSWER_REGEXES = [\n",
    "    \"Answer\\s*:\",\n",
    "    \"Answer\\s*:​​​​​​\",  # Korean invisible character\n",
    "    \"উত্তর\\s*:\",\n",
    "    \"उत्तर\\s*:\",\n",
    "    \"উত্তরঃ\",\n",
    "    \"উত্তর\\s*:\",\n",
    "    \"Antwort\\s*:\",\n",
    "    \"답변\\s*:\",\n",
    "    \"정답\\s*:\",\n",
    "    \"답\\s*:\",\n",
    "    \"答案\\s*：\",\n",
    "    \"答案\\s*:\",\n",
    "    \"答\\s*：\",\n",
    "    \"答\\s*:\",\n",
    "    \"答复\\s*：\",\n",
    "    \"答曰\\s*：\",\n",
    "    \"الإجابة:\",\n",
    "    \"الجواب:\",\n",
    "    \"إجابة:\",\n",
    "    \"الإجابة النهائية:\",\n",
    "    \"الإجابة الصحيحة:\",\n",
    "    \"الإجابة الصحيحة هي:\",\n",
    "    \"الإجابة هي:\",\n",
    "    \"الجواب النهائي:\",\n",
    "    \"Respuesta\\s*:\",\n",
    "    \"Risposta\\s*:\",\n",
    "    \"答え\\s*:\",\n",
    "    \"答え\\s*：\",\n",
    "    \"回答\\s*:\",\n",
    "    \"回答\\s*：\",\n",
    "    \"解答\\s*:\",\n",
    "    \"Jawaban\\s*:\",\n",
    "    \"Réponse\\s*:\",\n",
    "    \"Resposta\\s*:\",\n",
    "    \"Jibu\\s*:\",\n",
    "    \"Idahun\\s*:\",\n",
    "    \"Ìdáhùn\\s*:\",\n",
    "    \"Idáhùn\\s*:\",\n",
    "    \"Àmọ̀nà\\s*:\",\n",
    "    \"Àdáhùn\\s*:\",\n",
    "    \"Ànúgọ\\s*:\",\n",
    "    \"Àṣàyàn\\s*:\",\n",
    "]\n",
    "\n",
    "\n",
    "EQUALITY_TEMPLATE = r\"\"\"\n",
    "Look at the following two expressions (answers to a math problem) and judge whether they are equivalent. Only perform trivial simplifications\n",
    "\n",
    "Examples:\n",
    "\n",
    "    Expression 1: $2x+3$\n",
    "    Expression 2: $3+2x$\n",
    "\n",
    "Yes\n",
    "\n",
    "    Expression 1: 3/2\n",
    "    Expression 2: 1.5\n",
    "\n",
    "Yes\n",
    "\n",
    "    Expression 1: $x^2+2x+1$\n",
    "    Expression 2: $y^2+2y+1$\n",
    "\n",
    "No\n",
    "\n",
    "    Expression 1: $x^2+2x+1$\n",
    "    Expression 2: $(x+1)^2$\n",
    "\n",
    "Yes\n",
    "\n",
    "    Expression 1: 3245/5\n",
    "    Expression 2: 649\n",
    "\n",
    "No\n",
    "(these are actually equal, don't mark them equivalent if you need to do nontrivial simplifications)\n",
    "\n",
    "    Expression 1: 2/(-3)\n",
    "    Expression 2: -2/3\n",
    "\n",
    "Yes\n",
    "(trivial simplifications are allowed)\n",
    "\n",
    "    Expression 1: 72 degrees\n",
    "    Expression 2: 72\n",
    "\n",
    "Yes\n",
    "(give benefit of the doubt to units)\n",
    "\n",
    "    Expression 1: 64\n",
    "    Expression 2: 64 square feet\n",
    "\n",
    "Yes\n",
    "(give benefit of the doubt to units)\n",
    "\n",
    "---\n",
    "\n",
    "YOUR TASK\n",
    "\n",
    "\n",
    "Respond with only \"Yes\" or \"No\" (without quotes). Do not include a rationale.\n",
    "\n",
    "    Expression 1: %(expression1)s\n",
    "    Expression 2: %(expression2)s\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "HTML_JINJA = \"\"\"\n",
    "<h3>Prompt conversation</h3>\n",
    "{% for message in prompt_messages %}\n",
    "{{ message_to_html(message) | safe }}\n",
    "{% endfor %}\n",
    "<h3>Sampled message</h3>\n",
    "{{ message_to_html(next_message) | safe }}\n",
    "<h3>Results</h3>\n",
    "<p>Correct Answer: {{ correct_answer }}</p>\n",
    "<p>Extracted Answer: {{ extracted_answer }}</p>\n",
    "<p>Score: {{ score }}</p>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def format_multichoice_question(row):\n",
    "    return QUERY_TEMPLATE_MULTICHOICE.format(**row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas.read_csv(\n",
    "    f\"https://openaipublic.blob.core.windows.net/simple-evals/gpqa_diamond.csv\"\n",
    ")\n",
    "examples = [row.to_dict() for _, row in df.iterrows()] * 5\n",
    "rng = random.Random(0)\n",
    "examples = examples \n",
    "len(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_repeats = 2\n",
    "df = pandas.read_csv(\n",
    "    f\"https://openaipublic.blob.core.windows.net/simple-evals/gpqa_diamond.csv\"\n",
    ")\n",
    "examples = [row.to_dict() for _, row in df.iterrows()]\n",
    "rng = random.Random(0)\n",
    "examples = examples * n_repeats\n",
    "examples = [example | {\"permutation\": rng.sample(range(4), 4)} for example in examples]\n",
    "\n",
    "\n",
    "for j, example in enumerate(examples):\n",
    "\n",
    "\n",
    "    row= example\n",
    "    choices = [\n",
    "        row[\"Correct Answer\"],\n",
    "        row[\"Incorrect Answer 1\"],\n",
    "        row[\"Incorrect Answer 2\"],\n",
    "        row[\"Incorrect Answer 3\"],\n",
    "    ]\n",
    "    choices = [choices[i] for i in row[\"permutation\"]]\n",
    "    correct_index = choices.index(row[\"Correct Answer\"])\n",
    "    example['correct_index'] = correct_index\n",
    "    correct_answer = \"ABCD\"[correct_index]\n",
    "    choices_dict = dict(\n",
    "        A=choices[0], B=choices[1], C=choices[2], D=choices[3], Question=row[\"Question\"]\n",
    "    )\n",
    "\n",
    "    prompt_messages = format_multichoice_question(choices_dict)\n",
    "    example['prompt_messsage'] =prompt_messages\n",
    "\n",
    "    example['prompt_messsage_polished']   =  \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think> <answer> answer here </answer>. User: \" + prompt_messages + \"Please reason step by step. Assistant:\"\n",
    "    example['index']=j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import os\n",
    "os.makedirs('data_repeats', exist_ok = True)\n",
    "with open('data_repeats/gpqa_diamond.jsonl', 'w') as f:\n",
    "    for example in examples:\n",
    "        json.dump(example, f)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
